In this section, we present the interpolation algorithm that forms the core of
the proposed framework for probabilistic analysis of electronic systems. The
algorithm is based on the work in \cite{klimke2006} and \cite{ma2009}, and it
features a sparse-grid structure, hierarchical construction, and local
adaptivity. The benefits of these three features are interconnected and can be
summarized as follows: the ability to mitigate the curse of dimensionality and,
thereby, tackle high-dimensional problems; the ability to perform gradual
refinement of the approximation with a natural error control; and the ability to
make the refinement fine-grained and, hence, gain further efficiency.

Let $\f$ be a function that we would like to approximate. The function is
assumed to be in $\continuous([0, 1]^\nin)$, the space of continuous functions
in the unit hypercube $[0, 1]^\nin$. The assumption is a formality, and the
interpolation algorithm discussed in \sref{implementation} can be applied to
functions with finite discontinuities as well, which is actually the case in the
example given in \fref{motivation}. Furthermore, the domain $[0, 1]^\nin$ is
merely standardization rather than a restriction.

In what follows, we shall gradually construct an efficient interpolant for $\f$.
Efficiency here refers to the number of collocation nodes required to achieve a
certain accuracy level.

\subsection{Tensor Product} \slab{tensor-product}
\input{include/interpolation/tensor-product}

\subsection{Smolyak Algorithm} \slab{smolyak-algorithm}
\input{include/interpolation/smolyak-algorithm}

\subsection{Adaptivity} \slab{adaptivity}
\input{include/interpolation/adaptivity}

\subsection{Collocation Nodes} \slab{collocation-nodes}
\input{include/interpolation/collocation-nodes}

\subsection{Basis Functions} \slab{basis-functions}
\input{include/interpolation/basis-functions}

\subsection{Implementation} \slab{implementation}
\input{include/interpolation/implementation}

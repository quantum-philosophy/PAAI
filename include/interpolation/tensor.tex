In one dimension ($\nin = 1$), $\f$ is approximated by virtue of the following
interpolation formula:
\begin{equation} \elab{tensor-1d}
  \tensor{i}(\f) = \sum_{j \in \oindex_i} \f(\x_{ij}) \, \e_{ij}
\end{equation}
where $i \geq 0$ signifies the level of interpolation; $\X_i = \{ \x_{ij} \}_{j
\in \oindex_i} \subset [0, 1]$ are the collocation nodes; $\E_i = \{ \e_{ij}
\}_{j \in \oindex_i} \subset \continuous([0, 1])$ are the basis functions; and
$\oindex_i = \{ j - 1 \}_{j = 1}^{n_i}$ is an index set enumerating (starting
from zero) the nodes and functions of level $i$. The subscript $j \in \oindex_i$
is referred to as the order of a node or function. The choice of $\X_i$ and
$\E_i$ is important and will be discussed thoroughly later on.

In multiple dimensions ($\nin > 1$), $\f$ is approximated by the tensor product
of $\nin$ one-dimensional interpolants:
\begin{equation} \elab{tensor-nd}
  \tensor{\vi}(\f) = \left( \bigotimes_{k = 1}^\nin \tensor{i_k} \right)(\f) = \sum_{\vj \in \oindex_\vi} \f(\vx_{\vi\vj}) \, \e_{\vi\vj}
\end{equation}
where $\vi = (i_k)_{k = 1}^\nin$ and $\vj = (j_k)_{k = 1}^\nin$ are
(multi-)indices specifying levels and orders, respectively, for each of the
dimensions, and $\oindex_\vi = \oindex_{i_1} \times \cdots \times
\oindex_{i_\nin}$ is an index set obtained by computing the Cartesian product of
one-dimensional index sets. In the above formula,
\begin{align}
  \X_\vi &= \X_{i_1} \times \cdots \times \X_{i_\nin} \elab{collocation-nodes} \\
         &= \left\{ \vx_{\vi\vj} = (\x_{i_k j_k})_{k = 1}^\nin \right\}_{\vj \in \oindex_\vi} \subset [0, 1]^\nin \nonumber
\end{align}
and
\begin{equation} \elab{basis-functions}
  \E_\vi = \bigotimes_{k = 1}^\nin \E_{i_k}
         = \left\{ \e_{\vi\vj} = \bigotimes_{k = 1}^\nin \e_{i_k j_k} \right\}_{\vj \in \oindex_\vi} \subset \continuous([0, 1]^\nin)
\end{equation}
are the collocation nodes and basis functions, respectively, corresponding to
index $\vi$. In \eref{basis-functions}, for any $\vx \in [0, 1]^\nin$,
\begin{equation} \elab{basis-function}
  \e_{\vi\vj}(\vx) = \left( \bigotimes_{k = 1}^\nin \e_{i_k j_k} \right)(\vx) = \prod_{k = 1}^\nin \e_{i_k j_k}(\x_k).
\end{equation}
Finally, the cardinality of $\oindex_\vi$ is as follows:
\begin{equation} \elab{tensor-cardinality}
  \n_\vi = \card{\oindex_\vi} = \prod_{k = 1}^\nin \card{\oindex_{i_k}} = \prod_{k = 1}^\nin \n_{i_k}.
\end{equation}
Equation \eref{tensor-cardinality} elucidates the prohibited expense of the
tensor-product construction shown in \eref{tensor-nd} for multidimensional
problems: the number of nodes grows exponentially as $\nin$ increases. However,
\eref{tensor-nd} serves well as a building block for more efficient algorithms,
which we discuss next.

\begin{remark}
Each dimension can have its own rule defining the distribution of collocation
node with respect to each level. Similarly, the basis functions of one dimension
can differ from the basis functions of another. For simplicity and clarity of
presentation, this aspect is not covered in this paper.
\end{remark}

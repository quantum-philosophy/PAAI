\lettrine[findent=0.4em, nindent=0em]{\textbf{P}}{robabilistic analysis} of
multiprocessor systems is an extensive and diverse area, which is expanding with
an accelerating pace. The rapid growth is due to the fact that, as
multiprocessor systems become more sophisticated and refined, the deteriorating
impact of uncertainty becomes substantially more prominent, necessitating an
adequate treatment. The consequences of uncertainty range from a mild
performance degradation to severe faults and burnt silicon. In order to
facilitate the development of efficient and reliable designs, much research
effort has been devoted to uncertainty-aware modeling of various aspects of
multiprocessor systems.

Computer experiments \cite{santner2003} are of great use when uncertainty
quantification is concerned. Compared to other techniques for probabilistic
analysis, computer experiments are straightforward to undertake. The system at
hand is treated as completely opaque, and it only needs to be simulated a number
of times, following an adequate sampling strategy, in order to draw
well-grounded conclusions about the system's behavior. Consider, for instance,
the classical Monte Carlo (\abbr{MC}) sampling, which is arguably the most
famous and versatile approach to the analysis of stochastic systems. The
technique was introduced in the middle of the twentieth century and since then
has expanded into a broad family of methods that have had a tremendous impact
both in academia and in terms of industrial breakthroughs. The success of
\abbr{MC} sampling is due to the ease of implementation, independence of the
stochastic dimensionality, and asymptotic behavior of the quantities estimated
using this approach (the law of large numbers).

Note that designing for the worst case is often a poor solution as the system at
hand might easily end up being too conservative, over-designed
\cite{quinton2012}. Therefore, it is highly valuable to have access to a
probability distribution rather than corner cases.

The approach that we take belongs to the class of stochastic collocation
techniques \cite{xiu2010}. The major distinctive feature of stochastic
collocation is the usage of interpolation as a means of uncertainty
quantification, which should be contrasted with other techniques such as
polynomial-chaos (\abbr{PC}) expansions relying on regression. The application
of \abbr{PC} expansions is limited in this case due to the non-smoothness of the
response surface. More concretely, our framework is based on adaptive
hierarchical interpolation on sparse grids \cite{klimke2006, ma2009}.

The remainder of the paper is organized as follows. Section~\ref{sec:prior-work}
provides an overview of the prior work. In \sref{present-work}, we summarize the
contribution of the present paper. The preliminaries are given in
\sref{preliminaries}. The objective of our study is formulated in
\sref{problem-formulation}. The proposed framework is presented in
\sref{modeling}, \sref{interpolation}, and \sref{analysis}. The experimental
results are reported and discussed in \sref{experimental-results}, and
\sref{conclusion} concludes the paper.

Sampling methods would be a reasonable solution to probabilistic analysis of
electronic systems if electronic systems were inexpensive (with respect to the
computation time) to simulate. In order to eliminate or reduce the costs
associated with direct sampling, a number of techniques have been introduced.

\updated{The techniques are diverse and can be classified in many ways
including: 1)~the source of uncertainty; 2)~the metric of interest; and 3)~the
solution proposed in order to tackle the corresponding problem.} In what
follows, we shall discuss the prior work from the standpoint of the above three
aspects.

Let us first discuss physical sources of uncertainty and, more concretely,
process variation as it has been extensively studied. Circuit-level timing and
power analyses under process variation are undertaken in \cite{bhardwaj2008} by
means of polynomial chaos (\up{PC}) expansions \cite{xiu2010}. The work in
\cite{juan2012} models static steady-state temperature and accounts for process
variation by leveraging the linearity of Gaussian distributions and
time-invariant systems. A stochastic collocation \cite{xiu2010} approach to
static steady-state temperature analysis is given in \cite{lee2013}, which
relies on global interpolation using Newton polynomials. In \cite{ukhov2014},
transient temperature analysis is considered, and process variation is addressed
via \up{PC} expansions. The machinery of \up{PC} expansions is also utilized in
\cite{ukhov2015} in order to model dynamic steady-state temperature
\cite{ukhov2012} and to enhance reliability models.

Let us now turn to digital sources of uncertainty. In this context, timing
analysis has drawn the major attention \cite{quinton2012}. A seminal work on
response time analysis of periodic tasks with random execution times on
uniprocessors is reported in \cite{diaz2002}. A novel analytical solution to
this problem is given in \cite{tanasa2015}, which makes milder assumptions and
allows for addressing larger, previously unsolvable problems. The framework
proposed in \cite{santinelli2011} facilitates task scheduling by providing
probabilistic bounds on the resource given to a task flow and the resource
needed by that task flow; the approach is based on real-time calculus and is
applicable to electronic systems.

Studying the literature on probabilistic analysis of electronic systems, one can
note a pronounced trend: the generality and straightforwardness of sampling
methods tend to be lost. \updated{To elaborate, a technique typically:
1)~requires restrictive assumptions to be fulfilled such as the absence of
correlations, 2)~is tailored to one concrete metric such as the response time,
and 3)~requires substantial effort to be deployed.}

However, one should keep in mind what is practical. First of all, although
additional assumptions might make the mathematics analytically solvable, they
often do not hold in reality and oversimplify the model. An exact analytical
solution might also be extremely complex, requiring a lot of computational
resources upon evaluation. \updated{Furthermore, it is often the case that there
has been developed a robust simulator evaluating the metric at hand for the
deterministic scenario. Switching to probabilistic analysis based on analytical
approaches means discarding this battle-tested code and implementing something
else from scratch, which is wasteful and not desirable.}

Some of the techniques listed earlier in this section, in fact, preserve the
generality and straightforwardness of sampling methods. An example is the
uncertainty analysis presented in \cite{ukhov2015}. The reason is that the
construction of \up{PC} expansions in \cite{ukhov2015} is undertaken by means of
so-called nonintrusive spectral projections \cite{xiu2010}, which do not need to
look inside the ``black box,'' similar to sampling methods. However, as
motivated in \sref{introduction}, nonsmoothness is a serious problem for global
approximation based on polynomials. The convergence of \up{PC} expansions, for
instance, deteriorates substantially in such cases, requiring partitioning of
the stochastic space in order to alleviate the problem. Therefore, it is not
straightforward to apply such techniques as the one given in \cite{ukhov2015} in
the context of digital sources of uncertainty exhibiting nonsmoothness.

To conclude, the available techniques for probabilistic analysis of electronic
systems are restricted in use. Flexible, capable, and easy-to-deploy frameworks
are needed.

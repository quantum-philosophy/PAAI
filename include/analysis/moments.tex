Since the expected value and variance, which are defined in \eref{expectation}
and \eref{variance}, respectively, usually draw particular attention, we would
like to elaborate on them separately.

As shown in \sref{parameters}, $\g$ can be reparameterized in terms of
independent variables that are uniformly distributed on $[0, 1]^\nz$. This means
that the probability density function of $\vz$ simply equals to one. Therefore,
using \eref{expectation} and \eref{approximation}, we have
\[
  \expectation{\g} \approx \expectation{\approximation{\l}(\f)} = \int_{[0, 1]^\nz} \hspace{-1.5em} \approximation{\l}(\f)(\vz) \, \d\vz = \sum_{\vi \in \lindex_\l} \, \sum_{\vj \in \Delta\oindex_\vi} \surplus(\vx_{\vi\vj}) \, \w_{\vi\vj}
\]
where
\[
  \w_{\vi\vj} = \int_{[0, 1]^\nz} \e_{\vi\vj}(\vz) \, \d\vz = \prod_{k = 1}^{\nz} \int_0^1 \e_{i_k j_k}(\z_k) \, \d\z_k = \prod_{k = 1}^{\nz} \w_{i_k j_k}.
\]
In the above equation, $\w_{ij}$ is as shown in \eref{volume}. Consequently, we
have obtained an analytical formula for the expected value of $\g$, which does
not require any additional sampling.

Regarding the variance of $\g$, it can be seen in \eref{variance} that the
variance can be assembled from two components: the expected value of $\g$, which
we already have, and the expected value of $\g^2$, which we are missing. The
solution is to let $h = (\g, \g^2)$ be the metric instead of $\g$. Then the
expected values of both $\g$ and $\g^2$ will be available in analytical forms,
and the variance of $\g$ can be computed using \eref{variance}. This approach
can be generalized to probabilistic moments of higher orders.

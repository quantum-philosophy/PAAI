As noted earlier, performing Monte Carlo (\abbr{MC}) simulations is a compelling
approach to uncertainty quantification. We would readily apply an \abbr{MC}
method to study our quantity of interest $\g$ if only $\g$ had a negligible
cost, which it does not.

Recall that $\g$ is parameterized by the uncertain parameters $\vu$, and these
variables are the only source of randomness. Then, our solution to the
aforementioned quandary is as follows. First, we reparameterize $\g$ in terms of
an auxiliary random vector $\vz$ extracted from $\vu$; the necessity of this
stage will become clear later on. Second, we construct a light interpolant of
$\g$ by considering $\g$ as a deterministic function of $\vz$ and evaluating
$\g$ at a small number of strategically chosen points. Finally, we use the
constructed interpolant instead of $\g$ to perform sampling. The benefit of this
approach is in the number of invocations of $\g$: only a few evaluations of $\g$
are needed, and the rest of the analysis is powered by the interpolant, which
does have a negligible cost as opposed to $\g$.

Interpolation of high-dimensional functions, however, is a challenging task, and
it should be approached with a great care. One should first have a lucid
understand of what the final goal of the subsequent analysis is and choose the
quantity of interest accordingly. The quantity should generally be preprocessed
in order to make interpolation efficient and easy to undertake. In this regard,
domain-specific knowledge is invaluable. These aspects will be discussed in
detail in the rest of the paper.

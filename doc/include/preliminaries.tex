\subsection{Uncertainty Model} \slabel{uncertainty-model}
Let $(\O, \F, \P)$ and $\SI$ be a complete probability space \cite{durrett2010} and the space of square-integrable random variables (\rvs), respectively, where $\O$ is a set of outcomes, $\F$ is a $\sigma$-algebra of events on $\O$, and $\P: \F \to [0, 1]$ is a probability measure. The system depends on a number of uncertain parameters denoted by a vector of \rvs\ $\vU(\o) = (\U_1(\o), \dots, \U_\Nup(\o))^T: \O \to \real^\Nup$ where $\real = (-\infty, \infty)$ and $\vU \in \SI$. Since the \emph{joint} distribution function of $\vU(\o)$ is unrealistic to be obtained in practice, only the \emph{marginal} distribution functions $\CDF_{\U_i}: \real \to [0, 1]$ and a matrix of correlations $\mCorr_\vU \in [-1, 1]^{\Nup \times \Nup}$ are assumed to be given. $\mCorr_\vU$ captures either solely linear correlations, which is denoted by $\mLCorr_\vU$, via the Pearson's correlation coefficient (\ie, the matrix is the ordinary correlation matrix) or nonlinear correlations as well, which is denoted by $\mNCorr_\vU$, via a rank correlation coefficient (\eg, the Spearman's rho or Kendall's tau).

\subsection{Platform and Application Models} \slabel{platform-model} \slabel{application-model}
The system consists of two major components: a multiprocessor platform and an application. The platform is defined as a set of processing elements $\platform = \{ \processor_i: i = 1, \dots, \Npe \}$. The application is given as a directed acyclic graph $\application = (\tasks, \dependencies)$ where $\tasks = \{ \task_i: i = 1, \dots, \Nts \}$ is a set of tasks, and $\dependencies \subset \tasks \times \tasks$ is a set of data dependencies between $\tasks$. The binary matrix $\mM = (m_{ij}) \in \{ 0, 1 \}^{\Npe \times \Nts}$ defines the mapping of $\application$ onto $\platform$ where $m_{ij}$ is equal to one only if the $j$th task is to be executed on the $i$th processing element; otherwise, the element $m_{ij}$ is zero. For later reference, denote $\iProcessor_i = \{ j: m_{ij} = 1 \}$ the index set of the tasks mapped onto the $i$th processing element, and $\iTask_{i<} = \{ j: (j, i) \in \dependencies \}$ and $\iTask_{>i} = \{ j: (i, j) \in \dependencies \}$ the index sets of the tasks that are the immediate predecessors and successors of $\task_i$, respectively. Also, let $\size{\index}$ be the size of a set $\index$.

Each task $\task_i \in \tasks$ is characterized by its execution time (duration) $\D_i(\o) \in \real$ defined as a \rv\ in $\SI$. $\D_i(\o)$, $\forall i$, are assumed to be given as functionals of $\vU(\o)$, \ie, $\D_i(\o) = f(\vU(\o))$. In the simplest case, $\D_i(\o) \equiv \U_i(\o)$. Taking a certain amount of time $\d_i = \D_i(\o)$ for some $\o \in \O$, a task is assumed to reside in a certain power consumption mode. Therefore, the modes, denoted by $\PT_i(\o) \in \real$, $\forall i$, are assumed to be given as functions of the execution time of the tasks, \ie, $\PT_i(\o) = f(\D_i(\o))$. As such detailed dependencies are hard to capture, $\PT_i(\o)$ can reasonably be approximated by constants $\PT_i$.

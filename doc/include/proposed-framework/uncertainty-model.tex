The distribution of the uncertain parameters $(\X_i)$ is assumed to be given as
a set of marginal distribution functions
\[
  \{ \distribution_{\X_i}: i = 1, \dots, \nx \}
\]
and a copula \cite{nelsen2006}
\begin{align*}
  \copula_{\X}(\u_1, \dots, \u_\nx) &= \probabilityMeasure(\distribution_{\X_1}(\X_1) \leq \u_1, \dots, \distribution_{\X_\nx}(\X_\nx) \leq \u_\nx) \\
  &= \probabilityMeasure(\U_1 \leq \u_1, \dots, \U_\nx \leq \u_\nx).
\end{align*}
The copula is a uniform distribution function on $[0, 1]^\nx$ and captures the
dependencies between $(\X_i)$.

Each task $\task_i \in \tasks$ is ascribed a \rv\ $\E_i$ representing its
execution time. Let $\E = (\E_i)_{i=1}^{\nt}$. The random vector $\E$ is
assumed to be measurable with respect to $\sigma(\X)$, the $\sigma$-algebra
generated by $\X$ \cite{durrett2010}. Loosely speaking, this means that there
is a map $f: \real^\nx \to \real^\nt$ such that $\E = f(\X)$; $\E$ is known
whenever $\X$ is known. A trivial example is a one-to-one mapping between $\X$
and $\E$: $\X_i = \E_i$, for $i = 1, \dots, \nt$.
